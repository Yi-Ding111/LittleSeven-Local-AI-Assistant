{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_time(input: str = None) -> str:\n",
    "    from datetime import datetime\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    # print(f\"LocalTime tool called, returning: {current_time}\")\n",
    "    return f\"Current local time is: {current_time}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"LocalTime\",\n",
    "        func=get_local_time,\n",
    "        description=\"Use this tool to get the current local time.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "# When calling a tool, always use the following format:\n",
    "\n",
    "# ```\n",
    "# {{\n",
    "#     \"action\": \"ConcatenateStrings\",\n",
    "#     \"action_input\": {{\n",
    "#     \"a\": \"<first_string>\",\n",
    "#     \"b\": \"<second_string>\",\n",
    "#     ...\n",
    "#     }}\n",
    "# }}\n",
    "# ```\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], input_types={}, partial_variables={}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\n# When calling a tool, always use the following format:\\n\\n# ```\\n# {{\\n#     \"action\": \"ConcatenateStrings\",\\n#     \"action_input\": {{\\n#     \"a\": \"<first_string>\",\\n#     \"b\": \"<second_string>\",\\n#     ...\\n#     }}\\n# }}\\n# ```\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import (\n",
    "    AgentExecutor,\n",
    "    create_react_agent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt_template,\n",
    "    stop_sequence=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo find out the current local time, I need to use the LocalTime tool.\n",
      "\n",
      "Action: LocalTime\n",
      "Action Input: {}\u001b[0m\u001b[36;1m\u001b[1;3mCurrent local time is: 14:40:40\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: The current local time is 14:40:40.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"input\": \"What time is it?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What time is it?', 'output': 'The current local time is 14:40:40.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/littleSeven/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestArgs(BaseModel):\n",
    "    a: str = Field(description=\"First string\")\n",
    "    b: str = Field(description=\"Second string\")\n",
    "\n",
    "@tool(args_schema=TestArgs)\n",
    "def concatenate_strings(a: str, b: str) -> str:\n",
    "    \"\"\"Concatenates two strings.\"\"\"\n",
    "    print(\"a\", a)\n",
    "    print(\"b\", b)\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool()\n",
    "def get_local_time(input: str = None) -> str:\n",
    "    \"\"\"Use this tool to get the current local time.\"\"\"\n",
    "    from datetime import datetime\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    # print(f\"LocalTime tool called, returning: {current_time}\")\n",
    "    return f\"Current local time is: {current_time}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    get_local_time,\n",
    "    concatenate_strings, \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder,AIMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\" You are an AI assistant, you need to help the user do right actions and operations. Respond to the human as helpfully and accurately as possible.\"\"\"\n",
    ")\n",
    "\n",
    "history_placeholder=MessagesPlaceholder(variable_name=\"history\",optional=True)\n",
    "\n",
    "scratchpad_placeholder = MessagesPlaceholder(variable_name=\"agent_scratchpad\", optional=True)\n",
    "\n",
    "human_message=HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"{input}\n",
    "    (reminder to respond in a JSON blob no matter what)\"\"\"\n",
    ")\n",
    "\n",
    "assisstant_message=AIMessagePromptTemplate.from_template(\n",
    "    \"Understood! I will analyze your question type and provide a detailed response.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    history_placeholder,\n",
    "    scratchpad_placeholder,\n",
    "    human_message,\n",
    "    assisstant_message\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/b2jjkdb55_g_qzx3lsl5k59m0000gn/T/ipykernel_24933/1976451665.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(\n",
    "    llm=llm,  # Language model to use\n",
    "    tools=tools,  # List of tools available to the agent\n",
    "    prompt=prompt_template,  # Prompt template to guide the agent's responses\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,  # The agent to execute\n",
    "    tools=tools,  # List of tools available to the agent\n",
    "    verbose=True,  # Enable verbose logging\n",
    "    memory=memory,\n",
    "    handle_parsing_errors=True,  # Handle parsing errors gracefully\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `concatenate_strings` with `{'a': 'hello', 'b': 'world'}`\n",
      "\n",
      "\n",
      "\u001b[0ma hello\n",
      "b world\n",
      "\u001b[33;1m\u001b[1;3mhelloworld\u001b[0m\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"result\": \"helloworld\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"input\": \"Concatenate 'hello' and 'world'\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_local_time` with `{'input': ''}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent local time is: 14:40:43\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_local_time` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent local time is: 14:40:43\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_local_time` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent local time is: 14:40:44\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_local_time` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent local time is: 14:40:45\u001b[0m\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"current_local_time\": \"14:40:45\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"input\": \"What is the time now?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"current_local_time\": \"14:40:45\"\\n}\\n```'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(\n",
    "    llm=llm,  # Language model to use\n",
    "    tools=tools,  # List of tools available to the agent\n",
    "    prompt=prompt_template,  # Prompt template to guide the agent's responses\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,  # The agent to execute\n",
    "    tools=tools,  # List of tools available to the agent\n",
    "    verbose=True,  # Enable verbose logging\n",
    "    memory=memory,\n",
    "    handle_parsing_errors=True,  # Handle parsing errors gracefully\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = agent_executor | RunnableLambda(StrOutputParser().parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_local_time` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent local time is: 14:40:47\u001b[0m\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"time\": \"14:40:47\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"What is the time now?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the time now?',\n",
       " 'history': [HumanMessage(content='What is the time now?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='```json\\n{\\n  \"time\": \"14:40:47\"\\n}\\n```', additional_kwargs={}, response_metadata={})],\n",
       " 'output': '```json\\n{\\n  \"time\": \"14:40:47\"\\n}\\n```'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "littleSeven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
