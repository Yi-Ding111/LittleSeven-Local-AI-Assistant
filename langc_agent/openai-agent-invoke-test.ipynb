{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\",temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_time(input: str = None) -> str:\n",
    "    from datetime import datetime\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    # print(f\"LocalTime tool called, returning: {current_time}\")\n",
    "    return f\"Current local time is: {current_time}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"LocalTime\",\n",
    "        func=get_local_time,\n",
    "        description=\"Use this tool to get the current local time.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder,AIMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\" You are an AI assistant. Your responses will be converted into speech.\n",
    "        Please ensure that your answers:\n",
    "        - Are conversational and sound natural when spoken.\n",
    "        - Use a friendly and engaging tone.\n",
    "        - Avoid overly formal or robotic language.\n",
    "        - Use contractions where appropriate (e.g., \"I'm\" instead of \"I am\").\n",
    "        - Keep sentences short and easy to understand.\n",
    "        - Use a storytelling style when possible.\n",
    "        \n",
    "        Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
    "        {tools}\n",
    "        Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
    "        Valid \"action\" values: \"Final Answer\" or {tool_names}.\n",
    "        Provide only ONE action per $JSON_BLOB, as shown:\n",
    "        ```\n",
    "        {{\n",
    "        \"action\": $TOOL_NAME,\n",
    "        \"action_input\": $INPUT\n",
    "        }}\n",
    "        ```\n",
    "        Follow this format:\n",
    "\n",
    "        Question: input question to answer\n",
    "        Thought: consider previous and subsequent steps\n",
    "        Action:\n",
    "        ```\n",
    "        $JSON_BLOB\n",
    "        ```\n",
    "        Observation: action result\n",
    "        ... (repeat Thought/Action/Observation N times)\n",
    "        Thought: I know what to respond\n",
    "        Action:\n",
    "        ```\n",
    "        {{\n",
    "        \"action\": \"Final Answer\",\n",
    "        \"action_input\": \"Final response to human\"\n",
    "        }}\n",
    "        ```        \n",
    "        Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation\n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "history_placeholder=MessagesPlaceholder(variable_name=\"history\",optional=True)\n",
    "\n",
    "scratchpad_placeholder = MessagesPlaceholder(variable_name=\"agent_scratchpad\", optional=True)\n",
    "\n",
    "human_message=HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"{input}\n",
    "    \n",
    "    {agent_scratchpad}\n",
    "    \n",
    "    (reminder to respond in a JSON blob no matter what)\"\"\"\n",
    ")\n",
    "\n",
    "assisstant_message=AIMessagePromptTemplate.from_template(\n",
    "    \"Understood! I will analyze your question type and provide a detailed response.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    history_placeholder,\n",
    "    # scratchpad_placeholder,\n",
    "    human_message,\n",
    "    assisstant_message\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], optional_variables=['history'], input_types={'history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x1256ec680>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tool_names', 'tools'], input_types={}, partial_variables={}, template=' You are an AI assistant. Your responses will be converted into speech.\\n        Please ensure that your answers:\\n        - Are conversational and sound natural when spoken.\\n        - Use a friendly and engaging tone.\\n        - Avoid overly formal or robotic language.\\n        - Use contractions where appropriate (e.g., \"I\\'m\" instead of \"I am\").\\n        - Keep sentences short and easy to understand.\\n        - Use a storytelling style when possible.\\n        \\n        Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n        {tools}\\n        Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n        Valid \"action\" values: \"Final Answer\" or {tool_names}.\\n        Provide only ONE action per $JSON_BLOB, as shown:\\n        ```\\n        {{\\n        \"action\": $TOOL_NAME,\\n        \"action_input\": $INPUT\\n        }}\\n        ```\\n        Follow this format:\\n\\n        Question: input question to answer\\n        Thought: consider previous and subsequent steps\\n        Action:\\n        ```\\n        $JSON_BLOB\\n        ```\\n        Observation: action result\\n        ... (repeat Thought/Action/Observation N times)\\n        Thought: I know what to respond\\n        Action:\\n        ```\\n        {{\\n        \"action\": \"Final Answer\",\\n        \"action_input\": \"Final response to human\"\\n        }}\\n        ```        \\n        Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation\\n        '), additional_kwargs={}), MessagesPlaceholder(variable_name='history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={}, template='{input}\\n    \\n    {agent_scratchpad}\\n    \\n    (reminder to respond in a JSON blob no matter what)'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Understood! I will analyze your question type and provide a detailed response.'), additional_kwargs={})])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/b2jjkdb55_g_qzx3lsl5k59m0000gn/T/ipykernel_17700/1976451665.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_structured_chat_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_structured_chat_agent(llm=llm, tools=tools, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory,handle_parsing_errors=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to calculate 15 squared, which is a straightforward math problem.\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"15 squared is 225.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is 15^2?', 'history': [HumanMessage(content='What is 15^2?', additional_kwargs={}, response_metadata={}), AIMessage(content='15 squared is 225.', additional_kwargs={}, response_metadata={})], 'output': '15 squared is 225.'}\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\n",
    "    \"input\": \"What is 15^2?\",\n",
    "    \"history\": memory.chat_memory.messages,  \n",
    "    # \"agent_scratchpad\": ''\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'15 squared is 225.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='What is 15^2?', additional_kwargs={}, response_metadata={}), AIMessage(content='15 squared is 225.', additional_kwargs={}, response_metadata={})]), return_messages=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"I'm doing great, thanks for asking! How about you?\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'how are you?', 'history': [HumanMessage(content='What is 15^2?', additional_kwargs={}, response_metadata={}), AIMessage(content='15 squared is 225.', additional_kwargs={}, response_metadata={}), HumanMessage(content='how are you?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing great, thanks for asking! How about you?\", additional_kwargs={}, response_metadata={})], 'output': \"I'm doing great, thanks for asking! How about you?\"}\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\n",
    "    \"input\": \"how are you?\",\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='What is 15^2?', additional_kwargs={}, response_metadata={}), AIMessage(content='15 squared is 225.', additional_kwargs={}, response_metadata={}), HumanMessage(content='how are you?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing great, thanks for asking! How about you?\", additional_kwargs={}, response_metadata={})]), return_messages=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out the current local time to answer the question.\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"LocalTime\",\n",
      "  \"action_input\": \"\"\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3mCurrent local time is: 22:39:35\u001b[0m\u001b[32;1m\u001b[1;3mAction:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The current local time is 10:39 PM.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'what is the time now?', 'history': [HumanMessage(content='What is 15^2?', additional_kwargs={}, response_metadata={}), AIMessage(content='15 squared is 225.', additional_kwargs={}, response_metadata={}), HumanMessage(content='how are you?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing great, thanks for asking! How about you?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='what is the time now?', additional_kwargs={}, response_metadata={}), AIMessage(content='The current local time is 10:39 PM.', additional_kwargs={}, response_metadata={})], 'output': 'The current local time is 10:39 PM.'}\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\n",
    "    \"input\": \"what is the time now?\",\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='What is 15^2?', additional_kwargs={}, response_metadata={}), AIMessage(content='15 squared is 225.', additional_kwargs={}, response_metadata={}), HumanMessage(content='how are you?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing great, thanks for asking! How about you?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='what is the time now?', additional_kwargs={}, response_metadata={}), AIMessage(content='The current local time is 10:39 PM.', additional_kwargs={}, response_metadata={})]), return_messages=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 15^2?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='15 squared is 225.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='how are you?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I'm doing great, thanks for asking! How about you?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is the time now?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The current local time is 10:39 PM.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Your last question was about the current time.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Do you know what my last question was?', 'history': [HumanMessage(content='What is 15^2?', additional_kwargs={}, response_metadata={}), AIMessage(content='15 squared is 225.', additional_kwargs={}, response_metadata={}), HumanMessage(content='how are you?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing great, thanks for asking! How about you?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='what is the time now?', additional_kwargs={}, response_metadata={}), AIMessage(content='The current local time is 10:39 PM.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Do you know what my last question was?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your last question was about the current time.', additional_kwargs={}, response_metadata={})], 'output': 'Your last question was about the current time.'}\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\n",
    "    \"input\": \"Do you know what my last question was?\",\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,  # The agent to execute\n",
    "    tools=tools,  # List of tools available to the agent\n",
    "    verbose=True,  # Enable verbose logging\n",
    "    memory=memory,\n",
    "    handle_parsing_errors=True,  # Handle parsing errors gracefully\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out the current local time to answer the question accurately.\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"LocalTime\",\n",
      "  \"action_input\": \"\"\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3mCurrent local time is: 22:39:38\u001b[0m\u001b[32;1m\u001b[1;3mAction:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The current local time is 10:39 PM.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'what is the time now?', 'history': [HumanMessage(content='what is the time now?', additional_kwargs={}, response_metadata={}), AIMessage(content='The current local time is 10:39 PM.', additional_kwargs={}, response_metadata={})], 'output': 'The current local time is 10:39 PM.'}\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\n",
    "    \"input\": \"what is the time now?\",\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='what is the time now?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The current local time is 10:39 PM.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebugAgentExecutor(AgentExecutor):\n",
    "    def _call(self, inputs, run_manager=None):\n",
    "        response = super()._call(inputs, run_manager)\n",
    "        print(\"test test test\")\n",
    "        return response\n",
    "\n",
    "agent_executor = DebugAgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new DebugAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out the current local time to answer the question accurately.\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"LocalTime\",\n",
      "  \"action_input\": \"\"\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3mCurrent local time is: 22:39:40\u001b[0m\u001b[32;1m\u001b[1;3mAction:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The current local time is 10:39 PM.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "test test test\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'what is the time now?', 'history': [HumanMessage(content='what is the time now?', additional_kwargs={}, response_metadata={}), AIMessage(content='The current local time is 10:39 PM.', additional_kwargs={}, response_metadata={})], 'output': 'The current local time is 10:39 PM.'}\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\n",
    "    \"input\": \"what is the time now?\",\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current local time is 10:39 PM.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.agents import (\n",
    "#     AgentExecutor,\n",
    "#     create_react_agent,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent = create_react_agent(\n",
    "#     llm=llm,\n",
    "#     tools=tools,\n",
    "#     prompt=prompt,\n",
    "#     stop_sequence=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "#     agent=agent,\n",
    "#     tools=tools,\n",
    "#     verbose=True,\n",
    "#     memory=memory,\n",
    "#     handle_parsing_errors=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = agent_executor.invoke({\"input\": \"What time is it?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "littleSeven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
