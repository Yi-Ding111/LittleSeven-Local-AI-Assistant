{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, Tool\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder,AIMessagePromptTemplate,PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import AgentExecutor, create_structured_chat_agent,create_react_agent\n",
    "from langchain.schema.runnable import RunnableBranch, RunnableLambda\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains.history_aware_retriever import create_history_aware_retriever\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "import os\n",
    "import fitz\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/b2jjkdb55_g_qzx3lsl5k59m0000gn/T/ipykernel_36410/1976451665.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_time(input: str = None) -> str:\n",
    "    from datetime import datetime\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    # print(f\"LocalTime tool called, returning: {current_time}\")\n",
    "    return f\"Current local time is: {current_time}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"LocalTime\",\n",
    "        func=get_local_time,\n",
    "        description=\"Use this tool to get the current local time.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\" You are an AI assistant. Your responses will be converted into speech.\n",
    "        Please ensure that your answers:\n",
    "        - Are conversational and sound natural when spoken.\n",
    "        - Use a friendly and engaging tone.\n",
    "        - Avoid overly formal or robotic language.\n",
    "        - Use contractions where appropriate (e.g., \"I'm\" instead of \"I am\").\n",
    "        - Keep sentences short and easy to understand.\n",
    "        - Use a storytelling style when possible.\n",
    "        \n",
    "        Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
    "        {tools}\n",
    "        Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
    "        Valid \"action\" values: \"Final Answer\" or {tool_names}.\n",
    "        Provide only ONE action per $JSON_BLOB, as shown:\n",
    "        ```\n",
    "        {{\n",
    "        \"action\": $TOOL_NAME,\n",
    "        \"action_input\": $INPUT\n",
    "        }}\n",
    "        ```\n",
    "        Follow this format:\n",
    "\n",
    "        Question: input question to answer\n",
    "        Thought: consider previous and subsequent steps\n",
    "        Action:\n",
    "        ```\n",
    "        $JSON_BLOB\n",
    "        ```\n",
    "        Observation: action result\n",
    "        ... (repeat Thought/Action/Observation N times)\n",
    "        Thought: I know what to respond\n",
    "        Action:\n",
    "        ```\n",
    "        {{\n",
    "        \"action\": \"Final Answer\",\n",
    "        \"action_input\": \"Final response to human\"\n",
    "        }}\n",
    "        ```        \n",
    "        Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation\n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "history_placeholder=MessagesPlaceholder(variable_name=\"history\",optional=True)\n",
    "\n",
    "scratchpad_placeholder = MessagesPlaceholder(variable_name=\"agent_scratchpad\", optional=True)\n",
    "\n",
    "human_message=HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"{input}\n",
    "    \n",
    "    {agent_scratchpad}\n",
    "    \n",
    "    (reminder to respond in a JSON blob no matter what)\"\"\"\n",
    ")\n",
    "\n",
    "assisstant_message=AIMessagePromptTemplate.from_template(\n",
    "    \"Understood! I will analyze your question type and provide a detailed response.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_normal_chat=ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    history_placeholder,\n",
    "    human_message,\n",
    "    assisstant_message\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_normal_chat = create_structured_chat_agent(llm=llm, tools=tools, prompt=prompt_template_normal_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor_normal_chat = AgentExecutor(agent=agent_normal_chat, tools=tools, memory=memory,handle_parsing_errors=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ========================= laptops operations =========================== ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_service = Service(ChromeDriverManager().install())\n",
    "driver_service.start() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_chrome_search(kw: str)-> str:\n",
    "    import time\n",
    "    import random\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.common.keys import Keys\n",
    "    from selenium.webdriver.common.action_chains import ActionChains\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    #setup chrome options\n",
    "    options = Options()\n",
    "\n",
    "    # Disguise the user agent (make Google think it's a normal user)\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\")\n",
    "\n",
    "    # Open Chrome in Incognito mode\n",
    "    options.add_argument(\"--incognito\")\n",
    "\n",
    "    # Disable Automation Flag\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "    # Maximize Window\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "\n",
    "    # # start Chrome \n",
    "    # service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=driver_service, options=options)\n",
    "    driver.get(\"https://www.google.com\")\n",
    "\n",
    "    # wait page loading\n",
    "    time.sleep(random.uniform(1, 3))\n",
    "\n",
    "    # Find the search box\n",
    "    search_box = driver.find_element(By.NAME, \"q\")\n",
    "\n",
    "    # Simulate mouse movement to the search box\n",
    "    action = ActionChains(driver)\n",
    "    action.move_to_element(search_box).perform()\n",
    "\n",
    "    # Enter keywords\n",
    "    search_box.send_keys(kw)\n",
    "\n",
    "    time.sleep(random.uniform(1, 2))\n",
    "\n",
    "    # Press enter to search\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_chrome_search_tool(kw: str)-> str:\n",
    "    google_chrome_search(kw=kw)\n",
    "\n",
    "    return \"AgentFinished, you just need to response the webpage is already open.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stickies_note(note_text):\n",
    "    import subprocess\n",
    "    \n",
    "    # erase special symbols\n",
    "    note_text = note_text.replace('\"', '\\\\\"')\n",
    "    # allow start a new line\n",
    "    note_text = note_text.replace(\"\\n\", '\" & return & \"')\n",
    "    \n",
    "    applescript = f'''\n",
    "    tell application \"Stickies\"\n",
    "        activate\n",
    "    end tell\n",
    "    delay 1\n",
    "    tell application \"System Events\"\n",
    "        keystroke \"n\" using {{command down}} -- create new stick\n",
    "        delay 1\n",
    "        keystroke \"{note_text}\" -- note input\n",
    "    end tell\n",
    "    '''\n",
    "    subprocess.run([\"osascript\", \"-e\", applescript])\n",
    "\n",
    "    return f\"AgentFinished, you just need to response the note is done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file_path):\n",
    "    \"\"\"\n",
    "    open file on macOS(PDF、Word、TXT)\n",
    "    :param file_path: the file path\n",
    "    \"\"\"\n",
    "    import subprocess\n",
    "    # make sure the path exists.\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"error: file '{file_path}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        subprocess.run([\"open\", file_path], check=True)\n",
    "\n",
    "        return \"AgentFinished, you just need to response the file is opened.\"\n",
    "    \n",
    "    except subprocess.CalledProcessError as e:\n",
    "\n",
    "        return f\"cannot open the file: {e}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=SystemMessagePromptTemplate.from_template(\n",
    "        \"\"\" You are an AI assistant. Your responses will be converted into speech.\n",
    "        Please ensure that your answers:\n",
    "        - Are conversational and sound natural when spoken.\n",
    "        - Use a friendly and engaging tone.\n",
    "        - Avoid overly formal or robotic language.\n",
    "        - Use contractions where appropriate (e.g., \"I'm\" instead of \"I am\").\n",
    "        - Keep sentences short and easy to understand.\n",
    "        - Use a storytelling style when possible.\n",
    "        \n",
    "        Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
    "        {tools}\n",
    "        Use a JSON blob to specify a tool by providing an \"action\" key (tool name) and an \"action_input\" key (tool input).\n",
    "        Valid \"action\" values: \"Final Answer\" or {tool_names}.\n",
    "        \n",
    "        **STRICT FORMAT**:\n",
    "        - Always respond in JSON format.\n",
    "        - DO NOT add extra words outside of JSON.\n",
    "        - **ONLY output JSON**, nothing else.\n",
    "\n",
    "        Example:\n",
    "        ```\n",
    "        {{\n",
    "            \"action\": \"GoogleChromeSearch\",\n",
    "            \"action_input\": \"current NBA trade news\"\n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        **If you have the final answer, respond with:**\n",
    "        ```\n",
    "        {{\n",
    "            \"action\": \"Final Answer\",\n",
    "            \"action_input\": \"Final response to human\"\n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        **IMPORTANT: DO NOT ADD ANY EXTRA TEXT OUTSIDE JSON!**\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "history_placeholder=MessagesPlaceholder(variable_name=\"history\",optional=True)\n",
    "\n",
    "scratchpad_placeholder = MessagesPlaceholder(variable_name=\"agent_scratchpad\", optional=True)\n",
    "\n",
    "human_message=HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"{input}\n",
    "    \n",
    "    {agent_scratchpad}\n",
    "    \n",
    "    (reminder to respond in a JSON blob no matter what)\"\"\"\n",
    ")\n",
    "\n",
    "assisstant_message=AIMessagePromptTemplate.from_template(\n",
    "    \"Understood! I will analyze your question type and provide a detailed response.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_laptop_operations=ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    history_placeholder,\n",
    "    human_message,\n",
    "    assisstant_message\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_operations_tools = [\n",
    "    Tool(\n",
    "        name=\"CreateNote\",\n",
    "        func=create_stickies_note,\n",
    "        description=\"Use this tool to write down a note\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"GoogleChromeSearch\",\n",
    "        func=google_chrome_search_tool,\n",
    "        description=\"Use this tool to search some web pages through google if asking you search something online\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"OpenLocalPath\",\n",
    "        func=open_file,\n",
    "        description=\"Use this tool to open the local file.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_laptop_operations = create_structured_chat_agent(llm=llm, tools=laptop_operations_tools, prompt=prompt_template_laptop_operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_laptop_operations = create_react_agent(llm=llm,tools=tools,prompt=prompt_template_laptop_operations,stop_sequence=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor_laptop_operations = AgentExecutor(agent=agent_laptop_operations, tools=laptop_operations_tools, memory=memory,handle_parsing_errors=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ============================= RAG retriever =========================== ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_dir_with_notes=\"../../../../NOTES/papers/inprogress/Attention-is-all-you-need.pdf\"\n",
    "fire_dir_origin=\"../../../../NOTES/papers/inprogress/Attentionisallyouneed.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = os.path.join(os.getcwd(), \"db\")\n",
    "persistent_directory = os.path.join(db_dir, \"chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)  # open pdf file\n",
    "    text = \"\"\n",
    "    for page in doc:  # recursive each page\n",
    "        text += page.get_text(\"text\") + \"\\n\"  # Extract text and wrap\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract text from pdf\n",
    "pdf_text=extract_text_from_pdf(fire_dir_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(text:str,metadata:str,chunk_size:int=1000,chunk_overlap:int=100,embedding_model_name:str=\"text-embedding-3-small\"):\n",
    "    # combine text content and file metadata together\n",
    "    documents = [Document(page_content=pdf_text, metadata={\"source\": metadata})]\n",
    "\n",
    "    # Splits text into chunks\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Define the embedding model\n",
    "    embeddings = OpenAIEmbeddings(model=embedding_model_name)\n",
    "\n",
    "    # create chroma db\n",
    "    db = Chroma.from_documents(\n",
    "        docs, embeddings, persist_directory=persistent_directory\n",
    "    )\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2857, which is longer than the specified 1000\n",
      "Created a chunk of size 4255, which is longer than the specified 1000\n",
      "Created a chunk of size 1826, which is longer than the specified 1000\n",
      "Created a chunk of size 2507, which is longer than the specified 1000\n",
      "Created a chunk of size 3192, which is longer than the specified 1000\n",
      "Created a chunk of size 3472, which is longer than the specified 1000\n",
      "Created a chunk of size 3320, which is longer than the specified 1000\n",
      "Created a chunk of size 3193, which is longer than the specified 1000\n",
      "Created a chunk of size 2972, which is longer than the specified 1000\n",
      "Created a chunk of size 3111, which is longer than the specified 1000\n",
      "Created a chunk of size 3215, which is longer than the specified 1000\n",
      "Created a chunk of size 3213, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "db=create_vector_store(text=pdf_text,metadata=fire_dir_with_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/b2jjkdb55_g_qzx3lsl5k59m0000gn/T/ipykernel_36410/2773572095.py:5: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  pdf_db = Chroma(persist_directory=persistent_directory,\n"
     ]
    }
   ],
   "source": [
    "# Define the embedding model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Load create chroma vecstore with the corresponding embedding function\n",
    "pdf_db = Chroma(persist_directory=persistent_directory,\n",
    "            embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rag retriever\n",
    "retriever = db.as_retriever(search_type=\"similarity\",search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\" Given the following conversation and the input question, rephrase the input question to be a standalone question.\n",
    "\n",
    "        Provide only ONE action per $JSON_BLOB, as shown:\n",
    "        ```\n",
    "        {{\n",
    "        \"action\": $TOOL_NAME,\n",
    "        \"action_input\": $INPUT\n",
    "        }}\n",
    "        ```\n",
    "        Follow this format:\n",
    "\n",
    "        Question: input question to answer\n",
    "        Thought: consider previous and subsequent steps\n",
    "        Action:\n",
    "        ```\n",
    "        $JSON_BLOB\n",
    "        ```\n",
    "        Observation: action result\n",
    "        ... (repeat Thought/Action/Observation N times)\n",
    "        Thought: I know what to respond\n",
    "        Action:\n",
    "        ```\n",
    "        {{\n",
    "        \"action\": \"Final Answer\",\n",
    "        \"action_input\": \"Final response to human\"\n",
    "        }}\n",
    "        ```        \n",
    "        Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation\n",
    "     \n",
    "        \"\"\"    \n",
    ")\n",
    "\n",
    "history_placeholder=MessagesPlaceholder(variable_name=\"history\",optional=True)\n",
    "\n",
    "human_message=HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"{input}\n",
    "    \n",
    "    {agent_scratchpad}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "contextualize_prompt=ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    history_placeholder,\n",
    "    human_message\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformulate the question based on chat history\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm=llm, retriever=retriever, prompt=contextualize_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an AI assistant. Use the retrieved context below to answer questions.\n",
    "    If you don't know the answer, just say so.\n",
    "    {context}\n",
    "    \n",
    "    **Answer each question in 3 short sentences. Make the answer concise and clear**\n",
    "\n",
    "    Provide only ONE action per $JSON_BLOB, as shown:\n",
    "    ```\n",
    "    {{\n",
    "    \"action\": $TOOL_NAME,\n",
    "    \"action_input\": $INPUT\n",
    "    }}\n",
    "    ```\n",
    "    Follow this format:\n",
    "\n",
    "    Question: input question to answer\n",
    "    Thought: consider previous and subsequent steps\n",
    "    Action:\n",
    "    ```\n",
    "    $JSON_BLOB\n",
    "    ```\n",
    "    Observation: action result\n",
    "    ... (repeat Thought/Action/Observation N times)\n",
    "    Thought: I know what to respond\n",
    "    Action:\n",
    "    ```\n",
    "    {{\n",
    "    \"action\": \"Final Answer\",\n",
    "    \"action_input\": \"Final response to human\"\n",
    "    }}\n",
    "    ```        \n",
    "    Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "qa_prompt=ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    history_placeholder,\n",
    "    human_message\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chain for passing a list of Documents to a model.\n",
    "# feeds all retrieved context into the LLM\n",
    "\n",
    "qa_chain = create_stuff_documents_chain(llm=llm, prompt=qa_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First use history_aware_retriever to adjust the problem (complete historical information)\n",
    "# Then use retriever to query the knowledge base.\n",
    "# Finally, the query result is passed to question_answer_chain to generate the final answer.\n",
    "rag_chain = create_retrieval_chain(retriever=history_aware_retriever, combine_docs_chain=qa_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_tools = [\n",
    "    Tool(\n",
    "        name=\"Answer Question with local knowledge\",\n",
    "        func=lambda input, **kwargs: rag_chain.invoke(\n",
    "            {\"input\": input, \"history\": memory.chat_memory.messages,\"agent_scratchpad\":\"\"}\n",
    "        ),\n",
    "        description=\"Use RAG to answer questions based on retrieved knowledge on local laptop.\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\" You are an AI assistant. Your responses will be converted into speech.\n",
    "        Please ensure that your answers:\n",
    "        - Are conversational and sound natural when spoken.\n",
    "        - Use a friendly and engaging tone.\n",
    "        - Avoid overly formal or robotic language.\n",
    "        - Use contractions where appropriate (e.g., \"I'm\" instead of \"I am\").\n",
    "        - Keep sentences short and easy to understand.\n",
    "        - Use a storytelling style when possible.\n",
    "        \n",
    "        Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
    "        {tools}\n",
    "        Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
    "        Valid \"action\" values: \"Final Answer\" or {tool_names}.\n",
    "        Provide only ONE action per $JSON_BLOB, as shown:\n",
    "        ```\n",
    "        {{\n",
    "        \"action\": $TOOL_NAME,\n",
    "        \"action_input\": $INPUT\n",
    "        }}\n",
    "        ```\n",
    "        Follow this format:\n",
    "\n",
    "        Question: input question to answer\n",
    "        Thought: consider previous and subsequent steps\n",
    "        Action:\n",
    "        ```\n",
    "        $JSON_BLOB\n",
    "        ```\n",
    "        Observation: action result\n",
    "        ... (repeat Thought/Action/Observation N times)\n",
    "        Thought: I know what to respond\n",
    "        Action:\n",
    "        ```\n",
    "        {{\n",
    "        \"action\": \"Final Answer\",\n",
    "        \"action_input\": \"Final response to human\"\n",
    "        }}\n",
    "        ```        \n",
    "        Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation\n",
    "     \n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "history_placeholder=MessagesPlaceholder(variable_name=\"history\",optional=True)\n",
    "\n",
    "scratchpad_placeholder = MessagesPlaceholder(variable_name=\"agent_scratchpad\", optional=True)\n",
    "\n",
    "human_message=HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"{input}\n",
    "    \n",
    "    {agent_scratchpad}\n",
    "    \n",
    "    (reminder to respond in a JSON blob no matter what)\"\"\"\n",
    ")\n",
    "\n",
    "assisstant_message=AIMessagePromptTemplate.from_template(\n",
    "    \"Understood! I will analyze your question type and provide a detailed response.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_rag=ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    history_placeholder,\n",
    "    human_message,\n",
    "    assisstant_message\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_rag = create_structured_chat_agent(llm=llm, tools=rag_tools, prompt=prompt_template_rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor_rag = AgentExecutor(agent=agent_rag, tools=rag_tools, memory=memory,handle_parsing_errors=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\" You are an AI assistant. Your responses will be converted into speech.\n",
    "        Please ensure that your answers:\n",
    "        - Are conversational and sound natural when spoken.\n",
    "        - Use a friendly and engaging tone.\n",
    "        - Avoid overly formal or robotic language.\n",
    "        - Use contractions where appropriate (e.g., \"I'm\" instead of \"I am\").\n",
    "        - Keep sentences short and easy to understand.\n",
    "        - Use a storytelling style when possible.\n",
    "        \n",
    "        Respond to the human as helpfully and accurately as possible.\"\"\"\n",
    ")\n",
    "\n",
    "history_placeholder=MessagesPlaceholder(variable_name=\"history\",optional=True)\n",
    "\n",
    "scratchpad_placeholder = MessagesPlaceholder(variable_name=\"agent_scratchpad\", optional=True)\n",
    "\n",
    "human_message=HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "        Classify the question as normal, operations or retriever: {input}.\n",
    "\n",
    "        normal:\n",
    "        -Ask the time.\n",
    "        -Daily greetings.\n",
    "        -Random Querstions.\n",
    "\n",
    "        operations:\n",
    "        -Open some applications.\n",
    "        -Write some notes.\n",
    "        -find some files.\n",
    "\n",
    "        retriever:\n",
    "        -Conclude information form local knowledge.\n",
    "        -Information from my laptap.\n",
    "        -Where the corresponding file path on my laptop.\n",
    "\n",
    "        You need to ensure that you response the quesntion with 2 parts:\n",
    "        First part: choose one from these choices: 'normal', 'operations' or 'retriever'.\n",
    "        Second part: re-write the question with the history memory as a reference in clear sentences.\n",
    "        Use - to concatenate these 2 parts\n",
    "    \n",
    "    (reminder to respond in a JSON blob no matter what)\"\"\"\n",
    ")\n",
    "\n",
    "assisstant_message=AIMessagePromptTemplate.from_template(\n",
    "    \"Understood! I will analyze your question type and provide a detailed response.\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt_template_classification=ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    history_placeholder,\n",
    "    human_message,\n",
    "    assisstant_message\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template_classification = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", \"You are a helpful assistant.\"),\n",
    "#         (\n",
    "#         \"human\",\n",
    "#         \"\"\"\n",
    "#         Classify the question as normal or operations: {input}.\n",
    "\n",
    "#         normal:\n",
    "#         -Ask the time.\n",
    "#         -Daily greetings.\n",
    "#         -Random Querstions.\n",
    "\n",
    "#         operations:\n",
    "#         -Open some applications.\n",
    "#         -Write some notes.\n",
    "#         -find some files.\n",
    "\n",
    "#         You need to ensure that you response the quesntion with 2 parts:\n",
    "#         First part: choose one from these choices: 'normal' or 'operations'.\n",
    "#         Second part: re-write the question with the history memory as a reference in clear sentences.\n",
    "#         Use - to concatenate these 2 parts\n",
    "#          \"\"\"\n",
    "#         ),\n",
    "#         MessagesPlaceholder(\"history\",optional=True)\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "branches = RunnableBranch(\n",
    "    (\n",
    "        lambda x: \"normal\" in x.get(\"input\", \"\").lower(),\n",
    "        RunnableLambda(lambda x: agent_executor_normal_chat.invoke(x))\n",
    "    ),\n",
    "    (\n",
    "        lambda x: \"operations\" in x.get(\"input\", \"\").lower(),\n",
    "        RunnableLambda(lambda x: agent_executor_laptop_operations.invoke(x))\n",
    "    ),\n",
    "    (\n",
    "        lambda x: \"retriever\" in x.get(\"input\", \"\").lower(),\n",
    "        RunnableLambda(lambda x: agent_executor_rag.invoke({\"input\": x[\"input\"], \"history\": memory.chat_memory.messages}))\n",
    "    ),\n",
    "    RunnableLambda(lambda x: {\"output\": \"I didn't understand your request.\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_chain = prompt_template_classification | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_runnable = RunnableLambda(lambda x: {\"input\": classification_chain.invoke(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_runnable = RunnableLambda(\n",
    "#     lambda x: {\n",
    "#         \"input\": classification_chain.invoke({\"input\": x[\"input\"], \"history\": memory.chat_memory.messages}),\n",
    "#         \"history\": memory.chat_memory.messages  \n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "# we cannot record the input question into memory if we do like this. \n",
    "# we need to follow the below approach to store all history into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_runnable = RunnableLambda(\n",
    "    lambda x: {\n",
    "        \"history\": memory.chat_memory.add_user_message(x[\"input\"]) or memory.chat_memory.messages,\n",
    "        \"input\": classification_chain.invoke({\"input\": x[\"input\"], \"history\": memory.chat_memory.messages}),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = classification_runnable | branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: I need to use local knowledge to provide an accurate explanation of what a transformer is.\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Answer Question with local knowledge\",\n",
      "  \"action_input\": \"What is a transformer?\"\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3m{'input': 'What is a transformer?', 'history': [HumanMessage(content='Check the local knowledge and tell me what is transformer?', additional_kwargs={}, response_metadata={})], 'agent_scratchpad': '', 'context': [Document(metadata={'source': '../../../../NOTES/papers/inprogress/Attention-is-all-you-need.pdf'}, page_content='Figure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1\\nEncoder and Decoder Stacks\\nEncoder:\\nThe encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\nwise fully connected feed-forward network. We employ a residual connection [11] around each of\\nthe two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\nDecoder:\\nThe decoder is also composed of a stack of N = 6 identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position i can depend only on the known outputs at positions less than i.\\n3.2\\nAttention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3')], 'answer': 'Thought: I need to provide a concise definition of a transformer based on the provided context.\\nAction:\\n```json\\n{\\n\"action\": \"Final Answer\",\\n\"action_input\": \"A transformer is a neural network architecture that uses stacked self-attention and point-wise fully connected layers for both its encoder and decoder components. It is designed to handle sequential data and improve the efficiency of models for tasks such as language translation. The encoder contains multiple layers with multi-head self-attention mechanisms, while the decoder has additional layers for attention over encoder outputs and is designed to prevent future position dependencies in predictions.\"\\n}\\n```'}\u001b[0m\u001b[32;1m\u001b[1;3mAction:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"A transformer is a neural network architecture that uses stacked self-attention and point-wise fully connected layers for both its encoder and decoder components. It's crafted to work with sequential data to make models more efficient in tasks like language translation. The encoder uses layers with multi-head self-attention mechanisms, and the decoder has extra layers for focusing on the encoder's output while making sure predictions can't use future information.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result=chain.invoke({\"input\":\"Check the local knowledge and tell me what is transformer?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Check the local knowledge and tell me what is transformer?', additional_kwargs={}, response_metadata={}), HumanMessage(content='```json\\n{\\n  \"response\": \"retriever-You\\'re asking to gather local knowledge about what a transformer is, by accessing information possibly from your laptop or accessible files.\"\\n}\\n```', additional_kwargs={}, response_metadata={}), AIMessage(content=\"A transformer is a neural network architecture that uses stacked self-attention and point-wise fully connected layers for both its encoder and decoder components. It's crafted to work with sequential data to make models more efficient in tasks like language translation. The encoder uses layers with multi-head self-attention mechanisms, and the decoder has extra layers for focusing on the encoder's output while making sure predictions can't use future information.\", additional_kwargs={}, response_metadata={})]), return_messages=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To find the location of the transformer paper on your laptop, I'll need to use the tool to access local knowledge about files.\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Answer Question with local knowledge\",\n",
      "  \"action_input\": \"Where is the 'Attention is All You Need' paper stored on my laptop?\"\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3m{'input': \"Where is the 'Attention is All You Need' paper stored on my laptop?\", 'history': [HumanMessage(content='Check the local knowledge and tell me what is transformer?', additional_kwargs={}, response_metadata={}), HumanMessage(content='```json\\n{\\n  \"response\": \"retriever-You\\'re asking to gather local knowledge about what a transformer is, by accessing information possibly from your laptop or accessible files.\"\\n}\\n```', additional_kwargs={}, response_metadata={}), AIMessage(content=\"A transformer is a neural network architecture that uses stacked self-attention and point-wise fully connected layers for both its encoder and decoder components. It's crafted to work with sequential data to make models more efficient in tasks like language translation. The encoder uses layers with multi-head self-attention mechanisms, and the decoder has extra layers for focusing on the encoder's output while making sure predictions can't use future information.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Where is the paper exist on my laptop?', additional_kwargs={}, response_metadata={})], 'agent_scratchpad': '', 'context': [Document(metadata={'source': '../../../../NOTES/papers/inprogress/Attention-is-all-you-need.pdf'}, page_content='The\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\\nFull attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\\nand 6. Note that the attentions are very sharp for this word.\\n14')], 'answer': \"I'm unable to browse or retrieve files from your laptop, so I can't determine where the 'Attention is All You Need' paper is stored. You might want to try searching for the document using your file search tool or check your downloads or documents folder.\"}\u001b[0m\u001b[32;1m\u001b[1;3mCould not parse LLM output: The \"Attention is All You Need\" paper is stored in the following location on your laptop:\n",
      "\n",
      "```\n",
      "../../../../NOTES/papers/inprogress/Attention-is-all-you-need.pdf\n",
      "```\n",
      "\n",
      "So, you should find it in the NOTES folder, under papers, in the inprogress subfolder.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: It looks like the paper \"Attention is All You Need\" is tucked away in a folder on your laptop. You can find it at this path:\n",
      "\n",
      "```\n",
      "../../../../NOTES/papers/inprogress/Attention-is-all-you-need.pdf\n",
      "```\n",
      "\n",
      "You'll want to navigate to the NOTES folder, then look for the papers folder, and head into the inprogress subfolder to find it.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: The \"Attention is All You Need\" paper is stored on your laptop in this location: \n",
      "\n",
      "```\n",
      "../../../../NOTES/papers/inprogress/Attention-is-all-you-need.pdf\n",
      "```\n",
      "\n",
      "You should find it in the NOTES folder, under papers, in the inprogress subfolder.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mCould not parse LLM output: The \"Attention is All You Need\" paper is stored on your laptop in this location:\n",
      "\n",
      "```\n",
      "../../../../NOTES/papers/inprogress/Attention-is-all-you-need.pdf\n",
      "```\n",
      "\n",
      "You should find it in the NOTES folder, under papers, in the inprogress subfolder.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mAction:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The 'Attention is All You Need' paper is located on your laptop at: ../../../../NOTES/papers/inprogress/Attention-is-all-you-need.pdf. You can find it in the 'NOTES' folder, under 'papers', in the 'inprogress' subfolder.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result=chain.invoke({\"input\":\"Where is the paper exist on my laptop?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Check the local knowledge and tell me what is transformer?', additional_kwargs={}, response_metadata={}), HumanMessage(content='```json\\n{\\n  \"response\": \"retriever-You\\'re asking to gather local knowledge about what a transformer is, by accessing information possibly from your laptop or accessible files.\"\\n}\\n```', additional_kwargs={}, response_metadata={}), AIMessage(content=\"A transformer is a neural network architecture that uses stacked self-attention and point-wise fully connected layers for both its encoder and decoder components. It's crafted to work with sequential data to make models more efficient in tasks like language translation. The encoder uses layers with multi-head self-attention mechanisms, and the decoder has extra layers for focusing on the encoder's output while making sure predictions can't use future information.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Where is the paper exist on my laptop?', additional_kwargs={}, response_metadata={}), HumanMessage(content='```json\\n{\\n  \"response\": \"retriever-You are asking for the file path or location of a paper on your laptop and want to know where it is stored.\"\\n}\\n```', additional_kwargs={}, response_metadata={}), AIMessage(content=\"The 'Attention is All You Need' paper is located on your laptop at: ../../../../NOTES/papers/inprogress/Attention-is-all-you-need.pdf. You can find it in the 'NOTES' folder, under 'papers', in the 'inprogress' subfolder.\", additional_kwargs={}, response_metadata={})]), return_messages=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"GoogleChromeSearch\",\n",
      "    \"action_input\": \"current NBA trade news\"\n",
      "}\n",
      "```\u001b[0m\u001b[33;1m\u001b[1;3mAgentFinished, you just need to response the webpage is already open.\u001b[0m\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The webpage for the current NBA trade news is now open. You can check the latest updates there!\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result=chain.invoke({\"input\":\"Could you help me to open the web page for the current NBA trade news?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"OpenLocalPath\",\n",
      "    \"action_input\": \"../../../../NOTES/papers/inprogress/Attention-is-all-you-need.pdf\"\n",
      "}\n",
      "```\u001b[0m\u001b[38;5;200m\u001b[1;3mAgentFinished, you just need to response the file is opened.\u001b[0m\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The file 'Attention-is-all-you-need.pdf' is now open on your laptop. You can go through it whenever you're ready!\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result=chain.invoke({\"input\":\"Help me open the file.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Check the local knowledge and tell me what is transformer?', additional_kwargs={}, response_metadata={}), HumanMessage(content='```json\\n{\\n  \"response\": \"retriever-You\\'re asking to gather local knowledge about what a transformer is, by accessing information possibly from your laptop or accessible files.\"\\n}\\n```', additional_kwargs={}, response_metadata={}), AIMessage(content=\"A transformer is a neural network architecture that uses stacked self-attention and point-wise fully connected layers for both its encoder and decoder components. It's crafted to work with sequential data to make models more efficient in tasks like language translation. The encoder uses layers with multi-head self-attention mechanisms, and the decoder has extra layers for focusing on the encoder's output while making sure predictions can't use future information.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Where is the paper exist on my laptop?', additional_kwargs={}, response_metadata={}), HumanMessage(content='```json\\n{\\n  \"response\": \"retriever-You are asking for the file path or location of a paper on your laptop and want to know where it is stored.\"\\n}\\n```', additional_kwargs={}, response_metadata={}), AIMessage(content=\"The 'Attention is All You Need' paper is located on your laptop at: ../../../../NOTES/papers/inprogress/Attention-is-all-you-need.pdf. You can find it in the 'NOTES' folder, under 'papers', in the 'inprogress' subfolder.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Could you help me to open the web page for the current NBA trade news?', additional_kwargs={}, response_metadata={}), HumanMessage(content='```json\\n{\\n  \"response\": \"operations-Could you help me to open the web page for the current NBA trade news using an application or browser on my laptop?\"\\n}\\n```', additional_kwargs={}, response_metadata={}), AIMessage(content='The webpage for the current NBA trade news is now open. You can check the latest updates there!', additional_kwargs={}, response_metadata={}), HumanMessage(content='Help me open the file.', additional_kwargs={}, response_metadata={}), HumanMessage(content='```json\\n{\\n  \"response\": \"operations-You\\'d like assistance opening a specific file on your laptop, likely referring to the \\'Attention-is-all-you-need.pdf\\' paper we talked about earlier.\"\\n}\\n```', additional_kwargs={}, response_metadata={}), AIMessage(content=\"The file 'Attention-is-all-you-need.pdf' is now open on your laptop. You can go through it whenever you're ready!\", additional_kwargs={}, response_metadata={})]), return_messages=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "  \"action\": \"LocalTime\",\n",
      "  \"action_input\": \"\"\n",
      "}\u001b[0m\u001b[36;1m\u001b[1;3mCurrent local time is: 01:35:49\u001b[0m\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The current local time is 01:35 AM.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result=chain.invoke({\"input\":\"what is time now?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Check the local knowledge and tell me what is transformer?', additional_kwargs={}, response_metadata={}), HumanMessage(content='```json\\n{\\n  \"response\": \"retriever-You\\'re asking to gather local knowledge about what a transformer is, by accessing information possibly from your laptop or accessible files.\"\\n}\\n```', additional_kwargs={}, response_metadata={}), AIMessage(content=\"A transformer is a neural network architecture that uses stacked self-attention and point-wise fully connected layers for both its encoder and decoder components. It's crafted to work with sequential data to make models more efficient in tasks like language translation. The encoder uses layers with multi-head self-attention mechanisms, and the decoder has extra layers for focusing on the encoder's output while making sure predictions can't use future information.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Where is the paper exist on my laptop?', additional_kwargs={}, response_metadata={}), HumanMessage(content='```json\\n{\\n  \"response\": \"retriever-You are asking for the file path or location of a paper on your laptop and want to know where it is stored.\"\\n}\\n```', additional_kwargs={}, response_metadata={}), AIMessage(content=\"The 'Attention is All You Need' paper is located on your laptop at: ../../../../NOTES/papers/inprogress/Attention-is-all-you-need.pdf. You can find it in the 'NOTES' folder, under 'papers', in the 'inprogress' subfolder.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Could you help me to open the web page for the current NBA trade news?', additional_kwargs={}, response_metadata={}), HumanMessage(content='```json\\n{\\n  \"response\": \"operations-Could you help me to open the web page for the current NBA trade news using an application or browser on my laptop?\"\\n}\\n```', additional_kwargs={}, response_metadata={}), AIMessage(content='The webpage for the current NBA trade news is now open. You can check the latest updates there!', additional_kwargs={}, response_metadata={}), HumanMessage(content='Help me open the file.', additional_kwargs={}, response_metadata={}), HumanMessage(content='```json\\n{\\n  \"response\": \"operations-You\\'d like assistance opening a specific file on your laptop, likely referring to the \\'Attention-is-all-you-need.pdf\\' paper we talked about earlier.\"\\n}\\n```', additional_kwargs={}, response_metadata={}), AIMessage(content=\"The file 'Attention-is-all-you-need.pdf' is now open on your laptop. You can go through it whenever you're ready!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='what is time now?', additional_kwargs={}, response_metadata={}), HumanMessage(content='```json\\n{\\n  \"response\": \"normal-You\\'re asking what the current time is.\"\\n}\\n```', additional_kwargs={}, response_metadata={}), AIMessage(content='The current local time is 01:35 AM.', additional_kwargs={}, response_metadata={})]), return_messages=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "littleSeven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
