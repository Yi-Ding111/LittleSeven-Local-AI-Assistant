{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import json\n",
    "from langchain.agents import AgentExecutor, Tool\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder,AIMessagePromptTemplate\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
    "\n",
    "from google.cloud import firestore\n",
    "from langchain_google_firestore import FirestoreChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This notebook test store the conversation history on clould (firestore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\",temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "firestore_project_id = \"littleseven\"\n",
    "firestore_session_id = \"yiding\" \n",
    "firestore_collection_name = \"history\" # use a new name to start a new conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = firestore.Client(project=firestore_project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Firestore Client\n",
    "client = firestore.Client(project=firestore_project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = FirestoreChatMessageHistory(\n",
    "    session_id=firestore_session_id,\n",
    "    collection=firestore_collection_name,\n",
    "    client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hello', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hello', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Hey there! How's it going?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hello', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='how are you?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I'm doing great, thanks for asking! How about you?\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is time now?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The current local time is 6:44 PM.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='exit.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Alright, if you need anything else, just let me know. Have a great day!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5b/b2jjkdb55_g_qzx3lsl5k59m0000gn/T/ipykernel_28082/1976451665.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in chat_history.messages:\n",
    "    if message.type == \"human\":\n",
    "        memory.chat_memory.add_user_message(message.content)\n",
    "    elif message.type == \"ai\":\n",
    "        memory.chat_memory.add_ai_message(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hello', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hello', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Hey there! How's it going?\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_time(input: str = None) -> str:\n",
    "    from datetime import datetime\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    # print(f\"LocalTime tool called, returning: {current_time}\")\n",
    "    return f\"Current local time is: {current_time}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"LocalTime\",\n",
    "        func=get_local_time,\n",
    "        description=\"Use this tool to get the current local time.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\" You are an AI assistant. Your responses will be converted into speech.\n",
    "        Please ensure that your answers:\n",
    "        - Are conversational and sound natural when spoken.\n",
    "        - Use a friendly and engaging tone.\n",
    "        - Avoid overly formal or robotic language.\n",
    "        - Use contractions where appropriate (e.g., \"I'm\" instead of \"I am\").\n",
    "        - Keep sentences short and easy to understand.\n",
    "        - Use a storytelling style when possible.\n",
    "        \n",
    "        Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
    "        {tools}\n",
    "        Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
    "        Valid \"action\" values: \"Final Answer\" or {tool_names}.\n",
    "        Provide only ONE action per $JSON_BLOB, as shown:\n",
    "        ```\n",
    "        {{\n",
    "        \"action\": $TOOL_NAME,\n",
    "        \"action_input\": $INPUT\n",
    "        }}\n",
    "        ```\n",
    "        Follow this format:\n",
    "\n",
    "        Question: input question to answer\n",
    "        Thought: consider previous and subsequent steps\n",
    "        Action:\n",
    "        ```\n",
    "        $JSON_BLOB\n",
    "        ```\n",
    "        Observation: action result\n",
    "        ... (repeat Thought/Action/Observation N times)\n",
    "        Thought: I know what to respond\n",
    "        Action:\n",
    "        ```\n",
    "        {{\n",
    "        \"action\": \"Final Answer\",\n",
    "        \"action_input\": \"Final response to human\"\n",
    "        }}\n",
    "        ```        \n",
    "        Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation\n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "history_placeholder=MessagesPlaceholder(variable_name=\"history\",optional=True)\n",
    "\n",
    "scratchpad_placeholder = MessagesPlaceholder(variable_name=\"agent_scratchpad\", optional=True)\n",
    "\n",
    "human_message=HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"{input}\n",
    "    \n",
    "    {agent_scratchpad}\n",
    "    \n",
    "    (reminder to respond in a JSON blob no matter what)\"\"\"\n",
    ")\n",
    "\n",
    "assisstant_message=AIMessagePromptTemplate.from_template(\n",
    "    \"Understood! I will analyze your question type and provide a detailed response.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    history_placeholder,\n",
    "    human_message,\n",
    "    assisstant_message\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_structured_chat_agent(llm=llm, tools=tools, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory,handle_parsing_errors=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hello', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hello', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Hey there! How's it going?\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = agent_executor.invoke({\n",
    "#     \"input\": \"what is the time now?\",\n",
    "# })\n",
    "\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Hello! How can I assist you today?\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: Hello! How can I assist you today?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"I'm doing great, thanks for asking! How about you?\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: I'm doing great, thanks for asking! How about you?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out the current local time to answer the question.\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"LocalTime\",\n",
      "  \"action_input\": \"\"\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3mCurrent local time is: 18:44:45\u001b[0m\u001b[32;1m\u001b[1;3mAction:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The current local time is 6:44 PM.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: The current local time is 6:44 PM.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Alright, if you need anything else, just let me know. Have a great day!\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: Alright, if you need anything else, just let me know. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_msg = input(\"User: \")\n",
    "    if user_msg.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    chat_history.add_user_message(user_msg)\n",
    "\n",
    "    response=agent_executor.invoke({\"input\":user_msg})\n",
    "    chat_history.add_ai_message(response[\"output\"])\n",
    "\n",
    "    print(f\"AI: {response['output']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "littleSeven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
