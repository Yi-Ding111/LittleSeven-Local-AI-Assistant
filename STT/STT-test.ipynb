{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import whisper\n",
    "import sys\n",
    "\n",
    "common_path = '/Users/yiding/personal_projects/ML/github_repo/littleSeven/'\n",
    "if common_path not in sys.path:\n",
    "    sys.path.append(common_path)\n",
    "\n",
    "from common.config import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start recording...\n",
      "recording completed\n"
     ]
    }
   ],
   "source": [
    "FORMAT = pyaudio.paInt16\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# open the audio streaming\n",
    "stream = p.open(\n",
    "    format=FORMAT,\n",
    "    channels=cfg.audio_channels,\n",
    "    rate=cfg.sample_rate,\n",
    "    input=True,\n",
    "    frames_per_buffer=cfg.frame_chunk,\n",
    ")\n",
    "\n",
    "print(\"start recording...\")\n",
    "\n",
    "# record voice\n",
    "frames = []\n",
    "for i in range(0, int(cfg.sample_rate / cfg.frame_chunk * cfg.voice_duration)):\n",
    "    data = stream.read(cfg.frame_chunk)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"recording completed\")\n",
    "\n",
    "# stop audio streaming\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "# convert audio to NumPy array（16-bit PCM format）\n",
    "audio_data = np.frombuffer(b\"\".join(frames), dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  32,   74,   90, ..., -199, -191, -194], dtype=int16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert int-typed audio data into float-type and do normalization to [-1,1]\n",
    "audio_data_float = audio_data.astype(np.float32) / np.max(np.abs(audio_data))\n",
    "\n",
    "# adjust the audio to 16000HZ sample rate\n",
    "audio_data_resampled = librosa.resample(\n",
    "    audio_data_float, orig_sr=cfg.sample_rate, target_sr=16000\n",
    ")\n",
    "\n",
    "# normalize the audio to [-1,1]\n",
    "audio_data_resampled = audio_data_resampled / np.max(np.abs(audio_data_resampled))\n",
    "\n",
    "# prepare data as a tensor\n",
    "input_audio = torch.tensor(audio_data_resampled, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0091,  0.0242,  0.0211,  ..., -0.0557, -0.0594, -0.0446])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([79877])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tiny.en',\n",
       " 'tiny',\n",
       " 'base.en',\n",
       " 'base',\n",
       " 'small.en',\n",
       " 'small',\n",
       " 'medium.en',\n",
       " 'medium',\n",
       " 'large-v1',\n",
       " 'large-v2',\n",
       " 'large-v3',\n",
       " 'large',\n",
       " 'large-v3-turbo',\n",
       " 'turbo']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/littleSeven/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "## transcribe speech to text\n",
    "\n",
    "# load whisper model\n",
    "model = whisper.load_model(\n",
    "    name=cfg.whisper_model_name, download_root=cfg.whisper_model_path\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/littleSeven/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Hello Hello Hello How are you?\n"
     ]
    }
   ],
   "source": [
    "result = model.transcribe(input_audio)\n",
    "\n",
    "# print output\n",
    "print(\"text:\", result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/littleSeven/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## IF using whisper package, it would be quite slow when runing model.\n",
    "# So try the transformer package and send the model to MPS for acceleration\n",
    "\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "# load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\",cache_dir='./whisper_model')\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\",cache_dir='./whisper_model')\n",
    "model.config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = processor(input_audio, sampling_rate=16000, return_tensors=\"pt\").input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acceleration\n",
    "\n",
    "model=model.to('mps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features=input_features.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "predicted_ids = model.generate(input_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, hello, hello, how are you?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for ease of use, add transformer pipeline here\n",
    "\n",
    "# from transformers import pipeline\n",
    "\n",
    "# transformer_pipe=pipeline(task=\"automatic-speech-recognition\",processor=processor,model=model,tokenizer=processor.tokenizer,feature_extractor=processor.feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next i would add Voice Activity Detection (VAD) so that the process could recevice custom length voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the py-webrtcvad library\n",
    "# import webrtcvad\n",
    "\n",
    "# # Initialize a vad object\n",
    "# vad = webrtcvad.Vad()\n",
    "\n",
    "# # Run the VAD on 10 ms of silence and 16000 sampling rate \n",
    "# sample_rate = 16000\n",
    "# frame_duration = 10  # in ms\n",
    "\n",
    "# # Creating an audio frame of silence\n",
    "# frame = b'\\x00\\x00' * int(sample_rate * frame_duration / 1000)\n",
    "\n",
    "# # Detecting speech\n",
    "# print(f'Contains speech: {vad.is_speech(frame, sample_rate)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start recording...\n",
      "with no voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "end recording...\n",
      "save audio as ./output.wav\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import webrtcvad\n",
    "import numpy as np\n",
    "import collections\n",
    "import wave\n",
    "import time\n",
    "\n",
    "# set up parameters\n",
    "SAMPLE_RATE = 16000  \n",
    "FRAME_DURATION = 10  # duration tome for each frame，/ms\n",
    "FRAME_SIZE = int(SAMPLE_RATE * FRAME_DURATION / 1000) \n",
    "VAD_MODE = 1  # VAD mode\n",
    "SILENCE_LIMIT = 100  # voice tolerance\n",
    "SPEECH_TIMEOUT = 1 \n",
    "\n",
    "# initialize WebRTC VAD\n",
    "vad = webrtcvad.Vad(VAD_MODE)\n",
    "\n",
    "# initialize PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=pyaudio.paInt16,\n",
    "                channels=1,\n",
    "                rate=SAMPLE_RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=FRAME_SIZE)\n",
    "\n",
    "print(\"start recording...\")\n",
    "\n",
    "\n",
    "frames = collections.deque(maxlen=SAMPLE_RATE * 100)  \n",
    "no_speech_count = 0 \n",
    "start_time = time.time()  \n",
    "\n",
    "while True:\n",
    "    audio_frame = stream.read(FRAME_SIZE)  \n",
    "    frames.append(audio_frame)  \n",
    "    \n",
    "    audio_data = np.frombuffer(audio_frame, dtype=np.int16)\n",
    "    \n",
    "    is_speech = vad.is_speech(audio_data.tobytes(), SAMPLE_RATE)\n",
    "    \n",
    "    if is_speech:\n",
    "        print(\"detect voice...\")\n",
    "        no_speech_count = 0  \n",
    "        start_time = time.time() \n",
    "    else:\n",
    "        print(\"with no voice...\")\n",
    "        no_speech_count += 1 \n",
    "    \n",
    "    if no_speech_count >= SILENCE_LIMIT:\n",
    "        print(\"end recording...\")\n",
    "        break  \n",
    "\n",
    "# stop audio streaming\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "# save audio as wav file\n",
    "filename = \"./output.wav\"\n",
    "with wave.open(filename, 'wb') as wf:\n",
    "    wf.setnchannels(1)  # 单声道\n",
    "    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))  \n",
    "    wf.setframerate(SAMPLE_RATE)  \n",
    "    wf.writeframes(b''.join(frames))  \n",
    "\n",
    "print(f\"save audio as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start recording...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "detect voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "with no voice...\n",
      "end recording...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/littleSeven/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/littleSeven/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  Hello, hello, hello, how's going?\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import webrtcvad\n",
    "import numpy as np\n",
    "import collections\n",
    "import wave\n",
    "import io\n",
    "import whisper\n",
    "import time\n",
    "import librosa\n",
    "\n",
    "\n",
    "SAMPLE_RATE = 16000  \n",
    "FRAME_DURATION = 10  \n",
    "FRAME_SIZE = int(SAMPLE_RATE * FRAME_DURATION / 1000) \n",
    "VAD_MODE = 1  # VAD mode\n",
    "SILENCE_LIMIT = 100 \n",
    "\n",
    "# initilization WebRTC VAD\n",
    "vad = webrtcvad.Vad(VAD_MODE)\n",
    "\n",
    "# initilization PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# open audio streaming\n",
    "stream = p.open(format=pyaudio.paInt16,\n",
    "                channels=1,\n",
    "                rate=SAMPLE_RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=FRAME_SIZE)\n",
    "\n",
    "print(\"start recording...\")\n",
    "\n",
    "frames = collections.deque(maxlen=SAMPLE_RATE * 100)  \n",
    "no_speech_count = 0  \n",
    "start_time = time.time() \n",
    "\n",
    "while True:\n",
    "    audio_frame = stream.read(FRAME_SIZE)  \n",
    "    frames.append(audio_frame)  \n",
    "    \n",
    "    audio_data = np.frombuffer(audio_frame, dtype=np.int16)\n",
    "    \n",
    "    is_speech = vad.is_speech(audio_data.tobytes(), SAMPLE_RATE)\n",
    "    \n",
    "    if is_speech:\n",
    "        print(\"detect voice...\")\n",
    "        no_speech_count = 0  \n",
    "        start_time = time.time()  \n",
    "    else:\n",
    "        print(\"with no voice...\")\n",
    "        no_speech_count += 1 \n",
    "    \n",
    "    if no_speech_count >= SILENCE_LIMIT:\n",
    "        print(\"end recording...\")\n",
    "        break  \n",
    "\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "audio_in_memory = io.BytesIO()\n",
    "with wave.open(audio_in_memory, 'wb') as wf:\n",
    "    wf.setnchannels(1)  \n",
    "    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))  \n",
    "    wf.setframerate(SAMPLE_RATE)  \n",
    "    wf.writeframes(b''.join(frames))  \n",
    "\n",
    "# save audio data into memory\n",
    "audio_in_memory.seek(0)\n",
    "with wave.open(audio_in_memory, 'rb') as wf:\n",
    "    audio_data = np.frombuffer(wf.readframes(wf.getnframes()), dtype=np.int16)\n",
    "\n",
    "model = whisper.load_model(name=\"base\")  \n",
    "\n",
    "# convert audio data type to the format whisper model request\n",
    "input_audio = np.float32(audio_data) / 32768.0  # normalization to [-1, 1]\n",
    "\n",
    "result = model.transcribe(input_audio)\n",
    "\n",
    "# output\n",
    "print(\"text:\", result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# convert int-typed audio data into float-type and do normalization to [-1,1]\n",
    "audio_data_float = audio_data.astype(np.float32) / np.max(np.abs(audio_data))\n",
    "\n",
    "# adjust the audio to 16000HZ sample rate\n",
    "audio_data_resampled = librosa.resample(\n",
    "    audio_data_float, orig_sr=16000, target_sr=16000\n",
    ")\n",
    "\n",
    "# normalize the audio to [-1,1]\n",
    "audio_data_resampled = audio_data_resampled / np.max(np.abs(audio_data_resampled))\n",
    "\n",
    "# prepare data as a tensor\n",
    "input_audio = torch.tensor(audio_data_resampled, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0028, 0.0080, 0.0080,  ..., 0.0242, 0.0211, 0.0193])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transcribe speech to text\n",
    "\n",
    "# load whisper model\n",
    "model = whisper.load_model(\n",
    "    name=cfg.whisper_model_name, download_root=cfg.whisper_model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  Hello hello hello how's it going\n"
     ]
    }
   ],
   "source": [
    "result = model.transcribe(input_audio)\n",
    "\n",
    "# print output\n",
    "print(\"text:\", result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "# load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\",cache_dir='./whisper_model')\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\",cache_dir='./whisper_model')\n",
    "model.config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = processor(input_audio, sampling_rate=16000, return_tensors=\"pt\").input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acceleration\n",
    "\n",
    "model=model.to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features=input_features.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ids = model.generate(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" hello hello hello how's going\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "littleSeven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
